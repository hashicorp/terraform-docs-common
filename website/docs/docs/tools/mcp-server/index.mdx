---
page_title: Terraform MCP server overview
description: Learn about the Terraform model context protocol (MCP) server and how it can help you write Terraform configuration using AI.
---

⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️
> [!IMPORTANT]  
> **Documentation Update:** Product documentation previously located in `/website` has moved to the [`hashicorp/web-unified-docs`](https://github.com/hashicorp/web-unified-docs) repository, where all product documentation is now centralized. Please make contributions directly to `web-unified-docs`, since changes to `/website` in this repository will not appear on developer.hashicorp.com.
⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️⚠️

# Terraform MCP server overview

This topic provides an overview of the Terraform model context protocol (MCP) server, which helps you write Terraform configuration using an AI or LLM. The server requests information directly from the Terraform registry so that your model can formulate responses using provider code and documentation as the source of truth. 

@include 'beta.mdx'

## Introduction

MCP standardizes how AI models can discover and interact with external tools, applications, and data sources. You can configure MCP clients, such as an AI or LLM chat, to send requests through an MCP server so that the model can provide answers to prompts that it may not have been trained on. Refer to the [MCP documentation](https://modelcontextprotocol.io/introduction) for details about how MCP works. 

You can configure your AI model to connect to the Terraform MCP server so that it can request information about providers, modules, and other objects from data stored in the Terraform registry. When the Terraform MCP is available to your AI client, the model retrieves information from the most up-to-date source code stored in the registry, instead of relying on outdated training data. As a result, you can get more accurate and actionable information. 

Note that to use the server, your questions must pertain to provider configuration from the registry. The LLM uses other sources, such as content from the internet, to respond to general questions about Terraform configuration or requests to generate code.

## Workflow

- [Deploy the Terraform MCP server](/terraform/docs/tools/mcp-server/deploy)
- [Prompt your model](/terraform//docs/tools/mcp-server/prompt)

## Terraform MCP server tools

The Terraform MCP server runs in a Docker container on your local workstation and exposes functionality to clients using tools. The Terraform MCP server includes a set of tools that retrieve different types of information from the Terraform registry:

- `resolveProviderDocID`: Queries the Terraform Registry to find and list available documentation for a specific provider. This tool uses `serviceSlug` to return a list of provider document IDs with their titles and categories for resources, data sources, functions, or guides. 
- `getProviderDocs`: Fetches the complete documentation content for a specific provider resource, data source, or function using a document ID obtained from the `resolveProviderDocID` tool. Returns the raw documentation in markdown format.
- `searchModules`: Searches the Terraform Registry for modules based on the specified `moduleQuery` with pagination. Returns a list of module IDs with their names, descriptions, download counts, verification status, and publish dates. 
- `moduleDetails`: Retrieves detailed documentation for a module using a module ID obtained from the `searchModules` tool, including inputs, outputs, configuration, submodules, and examples.

## Release notes

For information about new releases, refer to the [Terraform MCP server repository](https://github.com/hashicorp/terraform-mcp-server/releases).

## Provide feedback

We want to hear from you. Complete the [Terraform MCP server feedback form](https://docs.google.com/forms/d/e/1FAIpQLSem_F9Spg89vQEq33-vjeXk-qZn930Dn3XSvcB2dBORgMHddA/viewform) to provide to help us improve this feature.