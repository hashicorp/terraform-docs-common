---
page_title: Terraform Cloud Kubernetes Operator v2 Migration Guide
description: >-
  Upgrade the Terraform Kubernetes Operator from version 1 to version 2.
---

# Terraform Cloud Kubernetes Operator v2 Migration Guide

~> **Compatibility warning**: Terraform Enterprise only supports version 2 of the Terraform Cloud Kubernetes Operator. If you use Terraform Enterprise, [refer to this tutorial](/terraform/tutorials/kubernetes/kubernetes-operator-v2) for installation guidance. 

To upgrade the Terraform Cloud Kubernetes Operator from version 1 to the Terraform Cloud Kubernetes Operator (version 2), there is a one-time process that you need to complete. This process upgrades the operator to the newest version and migrate your custom resources. 

## Prerequisites

The migration process requires the following tools to be installed locally:

- [kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl)
- [Helm](https://helm.sh/docs/intro/install/)

## Prepare for the upgrade

Configure an environment variable named `RELEASE_NAMESPACE` with the value of the namespace that the Helm chart is installed in.

```shell-session
$ export RELEASE_NAMESPACE=<NAMESPACE>
```

Next, create an environment variable named `RELEASE_NAME` with the value of the name that you gave your installation for the Helm chart.

```shell-session
$ export RELEASE_NAME=<INSTALLATION_NAME>
```

Before you migrate to Terraform Cloud Kubernetes Operator v2, you must first update v1 of the operator to the latest version, including the custom resource definitions.

```shell-session
$ helm upgrade --namespace ${RELEASE_NAMESPACE} ${RELEASE_NAME} hashicorp/terraform
```

Next, backup the workspace resources.

```shell-session
$ kubectl get workspace --all-namespaces -o yaml > backup_tfc_operator_v1.yaml
```

## Manifest schema migration

Version 2 of the Terraform Cloud Kubernetes operator renames and moves many existing fields. When you migrate, you must update your specification to match version 2's field names.

### Workspace controller

The table below lists the field mapping of the `Workspace` controller between v1 and v2 of the operator.

| Version 1 | Version 2 | Notes |
| --- | --- | --- |
| `apiVersion: app.terraform.io/v1alpha1` | `apiVersion: app.terraform.io/v1alpha2` | The `apiVersion` is now `v1alpha2`. |
| `kind: Workspace` | `kind: Workspace` |  |
| `metadata` | `metadata` |  |
| `spec.organization` | `spec.organization` |  |
| `spec.secretsMountPath` | `spec.token.secretKeyRef` | In v2 the operator keeps the HCP Terraform access token in a Kubernetes Secret. |
| `spec.vcs` | `spec.versionControl` | Renamed. Refer to the `versionControl` structure for details. |
| `spec.vcs.token_id` | `spec.versionControl.oAuthTokenID` | Renamed. Refer to the `versionControl` structure for details. |
| `spec.vcs.repo_identifier` | `spec.versionControl.repository` | Renamed. Refer to the `versionControl` structure for details. |
| `spec.vcs.branch` | `spec.versionControl.branch` |  |
| `spec.vcs.ingress_submodules` | `spec.workingDirectory` | Moved. |
| `spec.variables.[*]` | `spec.environmentVariables.[*]` OR `spec.terraformVariables.[*]` | We split variables into two possible places. In v1's CRD, if `spec.variables.environmentVariable` was `true`, migrate those variables to `spec.environmentVariables`. If `false`, migrate those variables to `spec.terraformVariables`. |
| `spec.variables.[*]key` | `spec.environmentVariables.[*]name` OR `spec.terraformVariables.[*]name` | The `key` field is renamed to `name`. |
| `spec.variables.[*]value` | `spec.environmentVariables.[*]value` OR `spec.terraformVariables.[*]value` |  |
| `spec.variables.[*]valueFrom` | `spec.environmentVariables.[*]valueFrom` OR `spec.terraformVariables.[*]valueFrom` |  |
| `spec.variables.[*]hcl` | `spec.environmentVariables.[*]hcl` OR `spec.terraformVariables.[*]hcl` |  |
| `spec.variables.sensitive` |  `spec.environmentVariables.[*]sensitive` OR `spec.terraformVariables.[*]sensitive` |  |
| `spec.variables.environmentVariable` | N/A | Removed, variables are split to `spec.environmentVariables` and `spec.terraformVariables`. |
| `spec.runTriggers.[*]` | `spec.runTriggers.[*]` |  Changes made to the `runTriggers` structure. |
| `spec.runTriggers.[*].sourceableName` | `spec.runTriggers.[*].name` | The `sourceableName` field is renamed to `name`. |
| `spec.sshKeyID` | `spec.sshKey.id` | The `sshKeyID` is moved to `spec.sshKey.id`. |
| `spec.outputs` | N/A | Removed. |
| `spec.terraformVersion` | `spec.terraformVersion` |  |
| `spec.notifications` | `spec.notifications` |  Changes made to the `notification` structure. |
| `spec.notifications.type` | `spec.notifications.type` |  |
| `spec.notifications.enabled` | `spec.notifications.enabled` |  |
| `spec.notifications.name` | `spec.notifications.name` |  |
| `spec.notifications.url` | `spec.notifications.url` |  |
| `spec.notifications.token` | `spec.notifications.token` |  |
| `spec.notifications.triggers.[*]` | `spec.notifications.triggers.[*]` |  |
| `spec.notifications.recepients.[*]` | `spec.notifications.emailAddesses.[*]` | The `recepients` field is renamed to `emailAddesses`. |
| `spec.notifications.users.[*]` | `spec.notifications.emailUsers.[*]` | The `users` field is renamed to `emailUsers`. |
| `spec.omitNamespacePrefix` | N/A | Removed. In v1 `spec.omitNamespacePrefix` is a boolean field and affects a Workspace name:<br/> - If it is `true` then a Workspace name will be generated as `metadata.namespace-metadata.name`.<br/> - If it is `false` then a Workspace name will be generated as `metadata.name`.<br/> In v2 a Workspace name must be explicitly set in `spec.name`. |
| `spec.agentPoolID` | `spec.agentPool.id` | The `agentPoolID` field is moved to `spec.agentPool.id`. |
| `spec.agentPoolName` | `spec.agentPool.name` | The `agentPoolName` field is moved to `spec.agentPool.name`. |
| `spec.module` | N/A | Removed. Modules are now configured with a separate `Module` CRD. Refer to the below migration mapping for more information. |

Below is an example of the differences is how variables are configured between v1 and v2.

<CodeBlockConfig filename="v1.yaml">

```yaml
apiVersion: app.terraform.io/v1alpha1
kind: Workspace
metadata:
  name: migration
  spec:
    variables:
      - key: username
        value: "user"
        hcl: true
        sensitive: false
        environmentVariable: false
      - key: SECRET_KEY
        value: "s3cr3t"
        hcl: false
        sensitive: false
        environmentVariable: true
```

</CodeBlockConfig>

In v2 of the operator, you must configure Terraform variables in `spec.terraformVariables` and environment variables `spec.environmentVariables`.

<CodeBlockConfig filename="v2">

```yaml
apiVersion: app.terraform.io/v1alpha2
kind: Workspace
metadata:
  name: migration
  spec:
    terraformVariables:
      - name: username
        value: "user"
        hcl: true
        sensitive: false
    environmentVariables:
      - name: SECRET_KEY
        value: "s3cr3t"
        hcl: false
        sensitive: false
```

</CodeBlockConfig>

### Module controller

Terraform Cloud Kubernetes Operator v2 configures modules in a new `Module` controller separate from the `Workspace` controller. Below is a template of a custom resource manifest:

```yaml
---
apiVersion: app.terraform.io/v1alpha2
kind: Module
metadata:
  name: <NAME>
spec:
  organization: <ORG-NAME>
  token:
    secretKeyRef:
      name: <SECRET-NAME>
      key: <KEY-NAME>
  name: operator
```

The table below details the mapping between the `Workspace` controller in v1 of the operator and the `Module` controller in v2 of the operator.

| Version 1 (Workspace CRD) | Version 2 (Module CRD) | Notes |
| --- | --- | --- |
| `spec.module` | N/A | In v2 of the operator a `Module` is a separate controller with its own CRD. |
| N/A | `spec.name: operator` | In v1 of the operator, the name of the generated module is hardcoded to `operator`. In v2, the default name of the generated module is `this`, however it can be changed. |
| `spec.module.source` | `spec.module.source` | This supports all Terraform [module sources](https://developer.hashicorp.com/terraform/language/modules/sources). |
| `spec.module.version` | `spec.module.version` | Refer to  [module sources](https://developer.hashicorp.com/terraform/language/modules/sources) for versioning information for each module source. |
| `spec.variables.[*]` | `spec.variables.[*].name` | Variable names should be included in the module. This is a reference to variables in the Workspace where the module will be executed. |
| `spec.outputs.[*].key` | `spec.outputs.[*].name` | Output names should be included in the module. This is a reference to the output variables produced by the module. |
| `status.workspaceID` OR `metadata.namespace-metadata.name` | `spec.workspace.id` OR `spec.workspace.name` | The workspace where the module will be executed. The workspace must be within the same organization. |

Below is an example migration of a `Module` between v1 and v2 of the operator:

<CodeBlockConfig filename="v1.yaml">

```yaml
apiVersion: app.terraform.io/v1alpha1
kind: Workspace
metadata:
  name: migration
spec:
  module:
    source: app.terraform.io/org-name/module-name/provider
    version: 0.0.42
  variables:
    - key: username
      value: "user"
      hcl: true
      sensitive: false
      environmentVariable: false
    - key: SECRET_KEY
      value: "s3cr3t"
      hcl: false
      sensitive: false
      environmentVariable: true
```

</CodeBlockConfig>

In v2 of the operator, the workspace and module are manage by separate controllers.

<CodeBlockConfig filename="workspace-v2.yaml">

  ```yaml
  apiVersion: app.terraform.io/v1alpha2
  kind: Workspace
  metadata:
    name: migration
    spec:
      terraformVariables:
        - name: username
          value: "user"
          hcl: true
          sensitive: false
      environmentVariables:
        - name: SECRET_KEY
          value: "s3cr3t"
          hcl: false
          sensitive: false
  ```

</CodeBlockConfig>

<CodeBlockConfig filename="module-v2.yaml">

```yaml
apiVersion: app.terraform.io/v1alpha2
kind: Module
metadata:
  name: migration
spec:
  name: operator
  module:
    source: app.terraform.io/org-name/module-name/provider
    version: 0.0.42
  workspace:
    name: migration
```

</CodeBlockConfig>

## Upgrade the operator

Download Workspace CRD patch A:

```shell-session
$ curl -sO https://raw.githubusercontent.com/hashicorp/terraform-cloud-operator/main/docs/migration/crds/workspaces_patch_a.yaml
```

View the changes that **patch A** will apply to the workspace CRD.

```shell-session
$ kubectl diff --filename workspaces_patch_a.yaml
```

Patch the workspace CRD with **patch A**. This patch adds `app.terraform.io/v1alpha2` support, but excludes `.status.runStatus` because it has a different format in `app.terraform.io/v1alpha1` and causes JSON unmarshalling issues.

~> **Warning** Once the patch is applied, Kubernetes will convert existing `app.terraform.io/v1alpha1` custom resources to `app.terraform.io/v1alpha2` according to the updated schema and v1 of the operator will no longer serve custom resources. You must update existing custom resources to satisfy the current schema. Refer to the tables above for a mapping of resource fields between v1 and v2 of the operator.

```shell-session
$ kubectl patch crd workspaces.app.terraform.io --patch-file workspaces_patch_a.yaml
```

Install the Operator v2 Helm chart with the `helm install` command. Be sure to set the `operator.watchedNamespaces` value to the list of namespaces your Workspace resources are deployed to. If this value is not provided, the operator will watch all namespaces in the Kubernetes cluster.

```shell-session
$ helm install \
  ${RELEASE_NAME} hashicorp/terraform-cloud-operator \
  --version 2.4.0 \
  --namespace ${RELEASE_NAMESPACE} \
  --set 'operator.watchedNamespaces={white,blue,red}' \
  --set controllers.agentPool.workers=5 \
  --set controllers.module.workers=5 \
  --set controllers.workspace.workers=5
```

Next, create a Kubernetes secret to store the HCP Terraform API token following the [Usage Guide](https://github.com/hashicorp/terraform-cloud-operator/blob/main/docs/usage.md#prerequisites). The API token can be copied from the Kubernetes secret that you created for v1 of the operator. By default, this is named `terraformrc`. Use the `kubectl get secret` command to get the API token.

```shell-session
$ kubectl --namespace ${RELEASE_NAMESPACE} get secret terraformrc -o json | jq '.data.credentials' | tr -d '"' | base64 -d
```

Update existing custom resources [according to the schema migration guidance](#manifest-schema-migration) and apply your changes.

```shell-session
$ kubectl apply --filename <UPDATED_V2_WORKSPACE_MANIFEST.yaml>
```

Download Workspace CRD patch B.

```shell-session
$ curl -sO https://raw.githubusercontent.com/hashicorp/terraform-cloud-operator/main/docs/migration/crds/workspaces_patch_b.yaml
```

View the changes that patch B applies to the workspace CRD.

```shell-session
$ kubectl diff --filename workspaces_patch_b.yaml
```

Patch workspace CRD with patch B. This patch adds `.status.runStatus` support, which was excluded in patch A.

```shell-session
$ kubectl patch crd workspaces.app.terraform.io --patch-file workspaces_patch_b.yaml
```

The v2 operator will fail to proceed if a custom resource has the v1 finalizer `finalizer.workspace.app.terraform.io`. If you encounter an error, check the logs for more information.

```shell-session
$ kubectl logs -f <POD_NAME>
```

Specifically, look for an error message such as the following.

```
ERROR	Migration	{"workspace": "default/<WORKSPACE_NAME>", "msg": "spec contains old finalizer finalizer.workspace.app.terraform.io"}
```

The `finalizer` exists to provide greater control over the migration process. Verify the custom resource, and when youâ€™re ready to migrate it, use the `kubectl patch` command to update the `finalizer` value.

```shell-session
$ kubectl patch workspace migration --type=merge --patch '{"metadata": {"finalizers": ["workspace.app.terraform.io/finalizer"]}}'
```

Review the operator logs once more and verify there are no error messages.

```shell-session
$ kubectl logs -f <POD_NAME>
```
The operator reconciles resources during the next sync period. This interval is set by the `operator.syncPeriod` configuration of the operator and defaults to five minutes. 

If you have any migrated `Module` custom resources, apply them now.

```shell-session
$ kubectl apply --filename <MIGRATED_V2_MODULE_MANIFEST.yaml>
```

In v2 of the operator, the `applyMethod` is set to `manual` by default. In this case, a new run in a managed workspace requires manual approval. Run the following command for each `Workspace` resource to change it to `auto` approval.

```shell-session
kubectl patch workspace <WORKSPACE_NAME> --type=merge --patch '{"spec": {"applyMethod": "auto"}}'
```
